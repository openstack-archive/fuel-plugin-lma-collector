---
lma_collector:
  alarms:
    - name: 'cpu-critical-controller'
      description: 'The CPU usage is too high (controller node)'
      severity: 'critical'
      enabled: 'true'
      trigger:
        logical_operator: 'or'
        rules:
          - metric: cpu_idle
            relational_operator: '<='
            threshold: 5
            window: 120
            periods: 0
            function: avg
          - metric: cpu_wait
            relational_operator: '>='
            threshold: 35
            window: 120
            periods: 0
            function: avg
    - name: 'cpu-warning-controller'
      description: 'The CPU usage is high (controller node)'
      severity: 'warning'
      enabled: 'true'
      trigger:
        logical_operator: 'or'
        rules:
          - metric: cpu_idle
            relational_operator: '<='
            threshold: 15
            window: 120
            periods: 0
            function: avg
          - metric: cpu_wait
            relational_operator: '>='
            threshold: 25
            window: 120
            periods: 0
            function: avg
    - name: 'swap-usage-critical'
      description: 'There is no more swap free space'
      severity: 'critical'
      enabled: 'true'
      trigger:
        logical_operator: 'or'
        rules:
          - metric: swap_free
            relational_operator: '=='
            threshold: 0
            window: 60
            periods: 0
            function: max
    - name: 'swap-activity-warning'
      description: 'The swap activity is high'
      severity: 'warning'
      enabled: 'true'
      trigger:
        logical_operator: 'or'
        rules:
          - metric: swap_io_in
            relational_operator: '>='
            threshold: 1048576 # 1 Mb/s
            window: 120
            periods: 0
            function: avg
          - metric: swap_io_out
            relational_operator: '>='
            threshold: 1048576 # 1 Mb/s
            window: 120
            periods: 0
            function: avg
    - name: 'swap-usage-warning'
      description: 'The swap free space is low'
      severity: 'warning'
      enabled: 'true'
      trigger:
        rules:
          - metric: swap_percent_used
            relational_operator: '>='
            threshold: 0.8
            window: 60
            periods: 0
            function: avg
    - name: 'cpu-critical-compute'
      description: 'The CPU usage is too high (compute node)'
      severity: 'critical'
      enabled: 'true'
      trigger:
        logical_operator: 'or'
        rules:
          - metric: cpu_wait
            relational_operator: '>='
            threshold: 30
            window: 120
            periods: 0
            function: avg
    - name: 'cpu-warning-compute'
      description: 'The CPU usage is high (compute node)'
      severity: 'warning'
      enabled: 'true'
      trigger:
        logical_operator: 'or'
        rules:
          - metric: cpu_wait
            relational_operator: '>='
            threshold: 20
            window: 120
            periods: 0
            function: avg
    - name: 'cpu-critical-rabbitmq'
      description: 'The CPU usage is too high (RabbitMQ node)'
      severity: 'critical'
      enabled: 'true'
      trigger:
        logical_operator: 'or'
        rules:
          - metric: cpu_idle
            relational_operator: '<='
            threshold: 5
            window: 120
            periods: 0
            function: avg
    - name: 'cpu-warning-rabbitmq'
      description: 'The CPU usage is high (RabbitMQ node)'
      severity: 'warning'
      enabled: 'true'
      trigger:
        logical_operator: 'or'
        rules:
          - metric: cpu_idle
            relational_operator: '<='
            threshold: 15
            window: 120
            periods: 0
            function: avg
    - name: 'cpu-critical-mysql'
      description: 'The CPU usage is too high (MySQL node)'
      severity: 'critical'
      enabled: 'true'
      trigger:
        logical_operator: 'or'
        rules:
          - metric: cpu_idle
            relational_operator: '<='
            threshold: 5
            window: 120
            periods: 0
            function: avg
    - name: 'cpu-warning-mysql'
      description: 'The CPU usage is high (MySQL node)'
      severity: 'warning'
      enabled: 'true'
      trigger:
        logical_operator: 'or'
        rules:
          - metric: cpu_idle
            relational_operator: '<='
            threshold: 15
            window: 120
            periods: 0
            function: avg
    - name: 'cpu-critical-storage'
      description: 'The CPU usage is too high (storage node)'
      severity: 'critical'
      enabled: 'true'
      trigger:
        logical_operator: 'or'
        rules:
          - metric: cpu_wait
            relational_operator: '>='
            threshold: 40
            window: 120
            periods: 0
            function: avg
          - metric: cpu_idle
            relational_operator: '<='
            threshold: 5
            window: 120
            periods: 0
            function: avg
    - name: 'cpu-warning-storage'
      description: 'The CPU usage is high (storage node)'
      severity: 'warning'
      enabled: 'true'
      trigger:
        logical_operator: 'or'
        rules:
          - metric: cpu_wait
            relational_operator: '>='
            threshold: 30
            window: 120
            periods: 0
            function: avg
          - metric: cpu_idle
            relational_operator: '<='
            threshold: 15
            window: 120
            periods: 0
            function: avg
    - name: 'cpu-critical-default'
      description: 'The CPU usage is too high'
      severity: 'critical'
      enabled: 'true'
      trigger:
        logical_operator: 'or'
        rules:
          - metric: cpu_wait
            relational_operator: '>='
            threshold: 35
            window: 120
            periods: 0
            function: avg
          - metric: cpu_idle
            relational_operator: '<='
            threshold: 5
            window: 120
            periods: 0
            function: avg
    - name: 'rabbitmq-disk-limit-critical'
      description: 'RabbitMQ has reached the free disk threshold. All producers are blocked'
      severity: 'critical'
      # If the local RabbitMQ instance is down, it will be caught by the
      # rabbitmq-check alarm
      no_data_policy: 'okay'
      enabled: 'true'
      trigger:
        logical_operator: 'or'
        rules:
          - metric: rabbitmq_remaining_disk
            relational_operator: '<='
            threshold: 0
            window: 20
            periods: 0
            function: min
    - name: 'rabbitmq-disk-limit-warning'
      description: 'RabbitMQ is getting close to the free disk threshold'
      severity: 'warning'
      # If the local RabbitMQ instance is down, it will be caught by the
      # rabbitmq-check alarm
      no_data_policy: 'okay'
      enabled: 'true'
      trigger:
        logical_operator: 'or'
        rules:
          - metric: rabbitmq_remaining_disk
            relational_operator: '<='
            threshold: 104857600 # 100MB
            window: 20
            periods: 0
            function: min
    - name: 'rabbitmq-memory-limit-critical'
      description: 'RabbitMQ has reached the memory threshold. All producers are blocked'
      severity: 'critical'
      # If the local RabbitMQ instance is down, it will be caught by the
      # rabbitmq-check alarm
      no_data_policy: 'okay'
      enabled: 'true'
      trigger:
        logical_operator: 'or'
        rules:
          - metric: rabbitmq_remaining_memory
            relational_operator: '<='
            threshold: 0
            window: 20
            periods: 0
            function: min
    - name: 'rabbitmq-memory-limit-warning'
      description: 'RabbitMQ is getting close to the memory threshold'
      severity: 'warning'
      # If the local RabbitMQ instance is down, it will be caught by the
      # rabbitmq-check alarm
      no_data_policy: 'okay'
      enabled: 'true'
      trigger:
        logical_operator: 'or'
        rules:
          - metric: rabbitmq_remaining_memory
            relational_operator: '<='
            threshold: 104857600 # 100MB
            window: 20
            periods: 0
            function: min
    - name: 'rabbitmq-queue-warning'
      description: 'The number of outstanding messages is too high'
      severity: 'warning'
      # If the local RabbitMQ instance is down, it will be caught by the
      # rabbitmq-check alarm
      no_data_policy: 'okay'
      enabled: 'true'
      trigger:
        logical_operator: 'or'
        rules:
          - metric: rabbitmq_messages
            relational_operator: '>='
            threshold: 200
            window: 120
            periods: 0
            function: avg
    - name: 'rabbitmq-pacemaker-down'
      description: 'The RabbitMQ cluster is down'
      severity: 'down'
      no_data_policy: 'skip' # the metric is only collected from the DC node
      enabled: 'true'
      trigger:
        logical_operator: 'and'
        rules:
          - metric: pacemaker_resource_percent
            fields:
              resource: rabbitmq
              status: up
            relational_operator: '=='
            threshold: 0
            window: 60
            periods: 0
            function: last
    - name: 'rabbitmq-pacemaker-critical'
      description: 'The RabbitMQ cluster is critical because less than half of the nodes are up'
      severity: 'critical'
      no_data_policy: 'skip' # the metric is only collected from the DC node
      enabled: 'true'
      trigger:
        logical_operator: 'and'
        rules:
          - metric: pacemaker_resource_percent
            fields:
              resource: rabbitmq
              status: up
            relational_operator: '<'
            threshold: 50
            window: 60
            periods: 0
            function: last
    - name: 'rabbitmq-pacemaker-warning'
      description: 'The RabbitMQ cluster is degraded because some RabbitMQ nodes are missing'
      severity: 'warning'
      no_data_policy: 'skip' # the metric is only collected from the DC node
      enabled: 'true'
      trigger:
        logical_operator: 'and'
        rules:
          - metric: pacemaker_resource_percent
            fields:
              resource: rabbitmq
              status: up
            relational_operator: '<'
            threshold: 100
            window: 60
            periods: 0
            function: last
    - name: 'apache-warning'
      description: 'There is no Apache idle workers available'
      severity: 'warning'
      enabled: 'true'
      trigger:
        logical_operator: 'or'
        rules:
          - metric: apache_idle_workers
            relational_operator: '=='
            threshold: 0
            window: 60
            periods: 0
            function: min
    - name: 'apache-check'
      description: 'Apache cannot be checked'
      severity: 'down'
      enabled: 'true'
      trigger:
        rules:
          - metric: apache_check
            relational_operator: '=='
            threshold: 0
            window: 60
            periods: 0
            function: last
    - name: 'log-fs-warning'
      description: "The log filesystem's free space is low"
      severity: 'warning'
      enabled: 'true'
      trigger:
        rules:
          - metric: fs_space_percent_free
            fields:
              fs: '/var/log'
            relational_operator: '<'
            threshold: 10
            window: 60
            periods: 0
            function: min
    - name: 'log-fs-critical'
      description: "The log filesystem's free space is too low"
      severity: 'critical'
      enabled: 'true'
      trigger:
        rules:
          - metric: fs_space_percent_free
            fields:
              fs: '/var/log'
            relational_operator: '<'
            threshold: 5
            window: 60
            periods: 0
            function: min
    - name: 'root-fs-warning'
      description: "The root filesystem's free space is low"
      severity: 'warning'
      enabled: 'true'
      trigger:
        rules:
          - metric: fs_space_percent_free
            fields:
              fs: '/'
            relational_operator: '<'
            threshold: 10
            window: 60
            periods: 0
            function: min
    - name: 'root-fs-critical'
      description: "The root filesystem's free space is too low"
      severity: 'critical'
      enabled: 'true'
      trigger:
        rules:
          - metric: fs_space_percent_free
            fields:
              fs: '/'
            relational_operator: '<'
            threshold: 5
            window: 60
            periods: 0
            function: min
    - name: 'mysql-fs-warning'
      description: "The MySQL filesystem's free space is low"
      severity: 'warning'
      enabled: 'true'
      trigger:
        rules:
          - metric: fs_space_percent_free
            fields:
              fs: '/var/lib/mysql'
            relational_operator: '<'
            threshold: 10
            window: 60
            periods: 0
            function: min
    - name: 'mysql-fs-critical'
      description: "The MySQL filesystem's free space is too low"
      severity: 'critical'
      enabled: 'true'
      trigger:
        rules:
          - metric: fs_space_percent_free
            fields:
              fs: '/var/lib/mysql'
            relational_operator: '<'
            threshold: 5
            window: 60
            periods: 0
            function: min
    - name: 'nova-fs-warning'
      description: "The filesystem's free space is low (compute node)"
      severity: 'warning'
      enabled: 'true'
      trigger:
        rules:
          - metric: fs_space_percent_free
            fields:
              fs: '/var/lib/nova'
            relational_operator: '<'
            threshold: 10
            window: 60
            periods: 0
            function: min
    - name: 'nova-fs-critical'
      description: "The filesystem's free space is too low (compute node)"
      severity: 'critical'
      enabled: 'true'
      trigger:
        rules:
          - metric: fs_space_percent_free
            fields:
              fs: '/var/lib/nova'
            relational_operator: '<'
            threshold: 5
            window: 60
            periods: 0
            function: min
    - name: 'other-fs-warning'
      description: "The filesystem's free space is low"
      severity: 'warning'
      enabled: 'true'
      no_data_policy: 'okay'
      trigger:
        rules:
          - metric: fs_space_percent_free
            fields:
              fs: '!= /var/lib/nova && != /var/log && != /var/lib/mysql && != / && !~ ceph%-%d+$'
            group_by: [fs]
            relational_operator: '<'
            threshold: 10
            window: 60
            periods: 0
            function: min
    - name: 'other-fs-critical'
      description: "The filesystem's free space is too low"
      severity: 'warning'
      enabled: 'true'
      no_data_policy: 'okay'
      trigger:
        rules:
          - metric: fs_space_percent_free
            fields:
              fs: '!= /var/lib/nova && != /var/log && != /var/lib/mysql && != / && !~ ceph%-%d+$'
            group_by: [fs]
            relational_operator: '<'
            threshold: 5
            window: 60
            periods: 0
            function: min
    - name: 'osd-disk-critical'
      description: "The filesystem's free space is too low (OSD disk)"
      severity: 'critical'
      enabled: 'true'
      trigger:
        rules:
          - metric: fs_space_percent_free
            fields:
              # Real FS is /var/lib/ceph/osd/ceph-0 but Collectd substituted '/' by '-'
              fs: '=~ ceph/%d+$'
            group_by: [fs]
            relational_operator: '<'
            threshold: 5
            window: 60
            periods: 0
            function: min
    - name: 'nova-api-http-errors'
      description: 'Too many 5xx HTTP errors have been detected on nova-api'
      severity: 'warning'
      enabled: 'true'
      trigger:
        logical_operator: 'or'
        rules:
          - metric: haproxy_backend_response_5xx
            fields:
              backend: 'nova-api'
            relational_operator: '>'
            threshold: 0
            window: 60
            periods: 1
            function: diff
    - name: 'nova-logs-error'
      description: 'Too many errors have been detected in Nova logs'
      severity: 'warning'
      no_data_policy: 'okay'
      enabled: 'true'
      trigger:
        logical_operator: 'or'
        rules:
          - metric: log_messages
            fields:
              service: 'nova'
              level: 'error'
            relational_operator: '>'
            threshold: 0.1
            window: 70
            periods: 0
            function: max
    - name: 'heat-api-http-errors'
      description: 'Too many 5xx HTTP errors have been detected on heat-api'
      severity: 'warning'
      enabled: 'true'
      trigger:
        logical_operator: 'or'
        rules:
          - metric: haproxy_backend_response_5xx
            fields:
              backend: 'heat-api'
            relational_operator: '>'
            threshold: 0
            window: 60
            periods: 1
            function: diff
    - name: 'heat-logs-error'
      description: 'Too many errors have been detected in Heat logs'
      severity: 'warning'
      no_data_policy: 'okay'
      enabled: 'true'
      trigger:
        logical_operator: 'or'
        rules:
          - metric: log_messages
            fields:
              service: 'heat'
              level: 'error'
            relational_operator: '>'
            threshold: 0.1
            window: 70
            periods: 0
            function: max
    - name: 'swift-api-http-errors'
      description: 'Too many 5xx HTTP errors have been detected on swift-api'
      severity: 'warning'
      enabled: 'true'
      trigger:
        logical_operator: 'or'
        rules:
          - metric: haproxy_backend_response_5xx
            fields:
              backend: 'swift-api || object-storage'
            relational_operator: '>'
            threshold: 0
            window: 60
            periods: 1
            function: diff
    - name: 'swift-logs-error'
      description: 'Too many errors have been detected in Swift logs'
      severity: 'warning'
      no_data_policy: 'okay'
      enabled: 'true'
      trigger:
        logical_operator: 'or'
        rules:
          - metric: log_messages
            fields:
              service: 'swift'
              level: 'error'
            relational_operator: '>'
            threshold: 0.1
            window: 70
            periods: 0
            function: max
    - name: 'cinder-api-http-errors'
      description: 'Too many 5xx HTTP errors have been detected on cinder-api'
      severity: 'warning'
      enabled: 'true'
      trigger:
        logical_operator: 'or'
        rules:
          - metric: haproxy_backend_response_5xx
            fields:
              backend: 'cinder-api'
            relational_operator: '>'
            threshold: 0
            window: 60
            periods: 1
            function: diff
    - name: 'cinder-logs-error'
      description: 'Too many errors have been detected in Cinder logs'
      severity: 'warning'
      no_data_policy: 'okay'
      enabled: 'true'
      trigger:
        logical_operator: 'or'
        rules:
          - metric: log_messages
            fields:
              service: 'cinder'
              level: 'error'
            relational_operator: '>'
            threshold: 0.1
            window: 70
            periods: 0
            function: max
    - name: 'glance-api-http-errors'
      description: 'Too many 5xx HTTP errors have been detected on glance-api'
      severity: 'warning'
      enabled: 'true'
      trigger:
        logical_operator: 'or'
        rules:
          - metric: haproxy_backend_response_5xx
            fields:
              backend: 'glance-api'
            relational_operator: '>'
            threshold: 0
            window: 60
            periods: 1
            function: diff
    - name: 'glance-logs-error'
      description: 'Too many errors have been detected in Glance logs'
      severity: 'warning'
      no_data_policy: 'okay'
      enabled: 'true'
      trigger:
        logical_operator: 'or'
        rules:
          - metric: log_messages
            fields:
              service: 'glance'
              level: 'error'
            relational_operator: '>'
            threshold: 0.1
            window: 70
            periods: 0
            function: max
    - name: 'neutron-api-http-errors'
      description: 'Too many 5xx HTTP errors have been detected on neutron-api'
      severity: 'warning'
      enabled: 'true'
      trigger:
        logical_operator: 'or'
        rules:
          - metric: haproxy_backend_response_5xx
            fields:
              backend: 'neutron-api'
            relational_operator: '>'
            threshold: 0
            window: 60
            periods: 1
            function: diff
    - name: 'neutron-logs-error'
      description: 'Too many errors have been detected in Neutron logs'
      severity: 'warning'
      no_data_policy: 'okay'
      enabled: 'true'
      trigger:
        logical_operator: 'or'
        rules:
          - metric: log_messages
            fields:
              service: 'neutron'
              level: 'error'
            relational_operator: '>'
            threshold: 0.1
            window: 70
            periods: 0
            function: max
    - name: 'keystone-response-time-duration'
      description: 'Keystone API is too slow'
      severity: 'warning'
      no_data_policy: 'okay'
      enabled: 'true'
      trigger:
        logical_operator: 'or'
        rules:
          - metric: openstack_keystone_http_response_times
            fields:
              http_method: '== GET || == POST'
              http_status: '!= 5xx'
            relational_operator: '>'
            threshold: 0.3
            window: 60
            periods: 0
            value: upper_90
            function: max
    - name: 'keystone-public-api-http-errors'
      description: 'Too many 5xx HTTP errors have been detected on keystone-public-api'
      severity: 'warning'
      enabled: 'true'
      trigger:
        logical_operator: 'or'
        rules:
          - metric: haproxy_backend_response_5xx
            fields:
              backend: 'keystone-public-api'
            relational_operator: '>'
            threshold: 0
            window: 60
            periods: 1
            function: diff
    - name: 'keystone-admin-api-http-errors'
      description: 'Too many 5xx HTTP errors have been detected on keystone-admin-api'
      severity: 'warning'
      enabled: 'true'
      trigger:
        logical_operator: 'or'
        rules:
          - metric: haproxy_backend_response_5xx
            fields:
              backend: 'keystone-admin-api'
            relational_operator: '>'
            threshold: 0
            window: 60
            periods: 1
            function: diff
    - name: 'horizon-web-http-errors'
      description: 'Too many 5xx HTTP errors have been detected on horizon'
      severity: 'warning'
      enabled: 'true'
      trigger:
        logical_operator: 'or'
        rules:
          - metric: haproxy_backend_response_5xx
            fields:
              backend: 'horizon-web || horizon-https'
            relational_operator: '>'
            threshold: 0
            window: 60
            periods: 1
            function: diff
    - name: 'keystone-logs-error'
      description: 'Too many errors have been detected in Keystone logs'
      severity: 'warning'
      no_data_policy: 'okay'
      enabled: 'true'
      trigger:
        logical_operator: 'or'
        rules:
          - metric: log_messages
            fields:
              service: 'keystone'
              level: 'error'
            relational_operator: '>'
            threshold: 0.1
            window: 70
            periods: 0
            function: max
    - name: 'mysql-node-connected'
      description: 'The MySQL service has lost connectivity with the other nodes'
      severity: 'critical'
      enabled: 'true'
      trigger:
        logical_operator: 'or'
        rules:
          - metric: mysql_cluster_connected
            relational_operator: '=='
            threshold: 0
            window: 30
            periods: 1
            function: min
    - name: 'mysql-node-ready'
      description: "The MySQL service isn't ready to serve queries"
      severity: 'critical'
      enabled: 'true'
      trigger:
        logical_operator: 'or'
        rules:
          - metric: mysql_cluster_ready
            relational_operator: '=='
            threshold: 0
            window: 30
            periods: 1
            function: min
    - name: 'ceph-health-critical'
      description: 'Ceph health is critical'
      severity: 'critical'
      enabled: 'true'
      trigger:
        rules:
          - metric: ceph_health
            relational_operator: '=='
            threshold: 3 # HEALTH_ERR
            window: 60
            function: max
    - name: 'ceph-health-warning'
      description: 'Ceph health is warning'
      severity: 'warning'
      enabled: 'true'
      trigger:
        rules:
          - metric: ceph_health
            relational_operator: '=='
            threshold: 2 # HEALTH_WARN
            window: 60
            function: max
    - name: 'ceph-capacity-critical'
      description: 'Ceph free capacity is too low'
      severity: 'critical'
      enabled: 'true'
      trigger:
        rules:
          - metric: ceph_pool_total_percent_free
            relational_operator: '<'
            threshold: 2
            window: 60
            function: max
    - name: 'ceph-capacity-warning'
      description: 'Ceph free capacity is low'
      severity: 'warning'
      enabled: 'true'
      trigger:
        rules:
          - metric: ceph_pool_total_percent_free
            relational_operator: '<'
            threshold: 5
            window: 60
            function: max
    - name: 'elasticsearch-health-critical'
      description: 'Elasticsearch cluster health is critical'
      severity: 'critical'
      enabled: 'true'
      trigger:
        rules:
          - metric: elasticsearch_cluster_health
            relational_operator: '=='
            threshold: 3 # red
            window: 60
            function: min
    - name: 'elasticsearch-health-warning'
      description: 'Elasticsearch health is warning'
      severity: 'warning'
      enabled: 'true'
      trigger:
        rules:
          - metric: elasticsearch_cluster_health
            relational_operator: '=='
            threshold: 2 # yellow
            window: 60
            function: min
    - name: 'elasticsearch-fs-warning'
      description: "The filesystem's free space is low (Elasticsearch node)"
      severity: 'warning'
      enabled: 'true'
      trigger:
        rules:
          - metric: fs_space_percent_free
            fields:
              fs: '/opt/es/data' # Real FS is /opt/es-data but Collectd substituted '/' by '-'
            relational_operator: '<'
            threshold: 20 # The low watermark for disk usage is 85% by default
            window: 60
            periods: 0
            function: min
    - name: 'elasticsearch-fs-critical'
      description: "The filesystem's free space is too low (Elasticsearch node)"
      severity: 'critical'
      enabled: 'true'
      trigger:
        rules:
          - metric: fs_space_percent_free
            fields:
              fs: '/opt/es/data' # Real FS is /opt/es-data but Collectd substituted '/' by '-'
            relational_operator: '<'
            threshold: 15 # The high watermark for disk usage is 90% by default
            window: 60
            periods: 0
            function: min
    - name: 'influxdb-fs-warning'
      description: "The filesystem's free space is low (InfluxDB node)"
      severity: 'warning'
      enabled: 'true'
      trigger:
        rules:
          - metric: fs_space_percent_free
            fields:
              fs: '/var/lib/influxdb'
            relational_operator: '<'
            threshold: 10
            window: 60
            periods: 0
            function: min
    - name: 'influxdb-fs-critical'
      description: "The filesystem's free space is too low (InfluxDB node)"
      severity: 'critical'
      enabled: 'true'
      trigger:
        rules:
          - metric: fs_space_percent_free
            fields:
              fs: '/var/lib/influxdb'
            relational_operator: '<'
            threshold: 5
            window: 60
            periods: 0
            function: min
    - name: 'haproxy-check'
      description: "HAProxy cannot be checked"
      severity: 'down'
      enabled: 'true'
      trigger:
        rules:
          - metric: haproxy_check
            relational_operator: '=='
            threshold: 0
            window: 60
            periods: 0
            function: last
    - name: 'rabbitmq-check'
      description: "RabbitMQ cannot be checked"
      # This alarm's severity is warning because the effective status of the
      # RabbitMQ cluster is computed by rabbitmq-pacemaker-* alarms.
      # This alarm is still useful because it will report the node(s) on which
      # RabbitMQ isn't running.
      severity: 'warning'
      enabled: 'true'
      trigger:
        rules:
          - metric: rabbitmq_check
            relational_operator: '=='
            threshold: 0
            window: 60
            periods: 0
            function: last
    - name: 'ceph-mon-check'
      description: "Ceph monitor cannot be checked"
      severity: 'down'
      enabled: 'true'
      trigger:
        rules:
          - metric: ceph_mon_check
            relational_operator: '=='
            threshold: 0
            window: 60
            periods: 0
            function: last
    - name: 'ceph-osd-check'
      description: "Ceph OSD cannot be checked"
      severity: 'down'
      enabled: 'true'
      trigger:
        rules:
          - metric: ceph_osd_check
            relational_operator: '=='
            threshold: 0
            window: 80  # The metric interval collection is 60s
            periods: 0
            function: last
    - name: 'pacemaker-check'
      description: "Pacemaker cannot be checked"
      severity: 'down'
      enabled: 'true'
      trigger:
        rules:
          - metric: pacemaker_check
            relational_operator: '=='
            threshold: 0
            window: 60
            periods: 0
            function: last
    - name: 'elasticsearch-check'
      description: "Elasticsearch cannot be checked"
      severity: 'down'
      enabled: 'true'
      trigger:
        rules:
          - metric: elasticsearch_check
            relational_operator: '=='
            threshold: 0
            window: 60
            periods: 0
            function: last
    - name: 'influxdb-check'
      description: "InfluxDB cannot be checked"
      severity: 'down'
      enabled: 'true'
      trigger:
        rules:
          - metric: influxdb_check
            relational_operator: '=='
            threshold: 0
            window: 60
            periods: 0
            function: last
    - name: 'libvirt-check'
      description: "Libvirt cannot be checked"
      severity: 'down'
      enabled: 'true'
      trigger:
        rules:
          - metric: libvirt_check
            relational_operator: '=='
            threshold: 0
            window: 60
            periods: 0
            function: last
    - name: 'memcached-check'
      description: "memcached cannot be checked"
      severity: 'down'
      enabled: 'true'
      trigger:
        rules:
          - metric: memcached_check
            relational_operator: '=='
            threshold: 0
            window: 60
            periods: 0
            function: last
    - name: 'mysql-check'
      description: "MySQL cannot be checked"
      severity: 'down'
      enabled: 'true'
      trigger:
        rules:
          - metric: mysql_check
            relational_operator: '=='
            threshold: 0
            window: 60
            periods: 0
            function: last
    - name: 'network-warning-dropped-rx'
      description: "Some received packets have been dropped"
      severity: 'warning'
      enabled: 'true'
      trigger:
        rules:
          - metric: if_dropped_rx
            relational_operator: '>'
            threshold: 100
            window: 60
            periods: 0
            function: avg
    - name: 'network-critical-dropped-rx'
      description: "Too many received packets have been dropped"
      severity: 'critical'
      enabled: 'true'
      trigger:
        rules:
          - metric: if_dropped_rx
            relational_operator: '>'
            threshold: 1000
            window: 60
            periods: 0
            function: avg
    - name: 'network-warning-dropped-tx'
      description: "Some transmitted packets have been dropped"
      severity: 'warning'
      enabled: 'true'
      trigger:
        rules:
          - metric: if_dropped_tx
            relational_operator: '>'
            threshold: 100
            window: 60
            periods: 0
            function: avg
    - name: 'network-critical-dropped-tx'
      description: "Too many transmitted packets have been dropped"
      severity: 'critical'
      enabled: 'true'
      trigger:
        rules:
          - metric: if_dropped_tx
            relational_operator: '>'
            threshold: 1000
            function: avg
            window: 60
    - name: 'instance-creation-time-warning'
      description: "Instance creation takes too much time"
      severity: 'warning'
      no_data_policy: 'okay' # This is a sporadic metric
      enabled: 'true'
      trigger:
        rules:
          - metric: openstack_nova_instance_creation_time
            relational_operator: '>'
            threshold: 20
            window: 600
            periods: 0
            function: avg
    - name: 'hdd-errors-critical'
      description: 'Errors on hard drive(s) have been detected'
      severity: 'critical'
      enabled: 'true'
      no_data_policy: okay
      trigger:
        rules:
          - metric: hdd_errors_rate
            group_by: ['device']
            relational_operator: '>'
            threshold: 0
            window: 60
            periods: 0
            function: max
    - name: 'total-nova-free-vcpu-warning'
      description: 'There is none VCPU available for new instances'
      severity: 'warning'
      enabled: 'true'
      no_data_policy: skip # the metric is only collected from the aggregator node
      trigger:
        rules:
          - metric: openstack_nova_total_free_vcpus
            relational_operator: '=='
            threshold: 0
            window: 60
            periods: 0
            function: max
    - name: 'total-nova-free-memory-warning'
      description: 'There is none memory available for new instances'
      severity: 'warning'
      enabled: 'true'
      no_data_policy: skip  # the metric is only collected from the aggregator node
      trigger:
        rules:
          - metric: openstack_nova_total_free_ram
            relational_operator: '=='
            threshold: 0
            window: 60
            periods: 0
            function: max

    # Following are the OpenStack service check API definitions and
    # also InfluxDB API
    - name: 'influxdb-api-check-failed'
      description: 'Endpoint check for InfluxDB is failed'
      severity: 'down'
      no_data_policy: 'skip' # the metric is only collected from the controller running the management VIP
      enabled: 'true'
      trigger:
        rules:
          - metric: http_check
            fields:
              service: 'influxdb-cluster'
            relational_operator: '=='
            threshold: 0
            window: 60
            periods: 0
            function: last
    - name: 'nova-api-check-failed'
      description: 'Endpoint check for nova-api is failed'
      severity: 'down'
      no_data_policy: 'skip' # the metric is only collected from the controller running the management VIP
      enabled: 'true'
      trigger:
        rules:
          - metric: openstack_check_api
            fields:
              service: 'nova-api'
            relational_operator: '=='
            threshold: 0
            window: 60
            periods: 0
            function: last
    - name: 'neutron-api-check-failed'
      description: 'Endpoint check for neutron-api is failed'
      severity: 'down'
      no_data_policy: 'skip' # the metric is only collected from the controller running the management VIP
      enabled: 'true'
      trigger:
        rules:
          - metric: openstack_check_api
            fields:
              service: 'neutron-api'
            relational_operator: '=='
            threshold: 0
            window: 60
            periods: 0
            function: last
    - name: 'cinder-api-check-failed'
      description: 'Endpoint check for cinder-api is failed'
      severity: 'down'
      no_data_policy: 'skip' # the metric is only collected from the controller running the management VIP
      enabled: 'true'
      trigger:
        rules:
          - metric: openstack_check_api
            fields:
              service: 'cinder-api'
            relational_operator: '=='
            threshold: 0
            window: 60
            periods: 0
            function: last
    - name: 'cinder-v2-api-check-failed'
      description: 'Endpoint check for cinder-v2-api is failed'
      severity: 'down'
      no_data_policy: 'skip' # the metric is only collected from the controller running the management VIP
      enabled: 'true'
      trigger:
        rules:
          - metric: openstack_check_api
            fields:
              service: 'cinder-v2-api'
            relational_operator: '=='
            threshold: 0
            window: 60
            periods: 0
            function: last
    - name: 'glance-api-check-failed'
      description: 'Endpoint check for glance-api is failed'
      severity: 'down'
      no_data_policy: 'skip' # the metric is only collected from the controller running the management VIP
      enabled: 'true'
      trigger:
        rules:
          - metric: openstack_check_api
            fields:
              service: 'glance-api'
            relational_operator: '=='
            threshold: 0
            window: 60
            periods: 0
            function: last
    - name: 'heat-api-check-failed'
      description: 'Endpoint check for heat-api is failed'
      severity: 'down'
      no_data_policy: 'skip' # the metric is only collected from the controller running the management VIP
      enabled: 'true'
      trigger:
        rules:
          - metric: openstack_check_api
            fields:
              service: 'heat-api'
            relational_operator: '=='
            threshold: 0
            window: 60
            periods: 0
            function: last
    - name: 'heat-cfn-api-check-failed'
      description: 'Endpoint check for heat-cfn-api is failed'
      severity: 'down'
      no_data_policy: 'skip' # the metric is only collected from the controller running the management VIP
      enabled: 'true'
      trigger:
        rules:
          - metric: openstack_check_api
            fields:
              service: 'heat-cfn-api'
            relational_operator: '=='
            threshold: 0
            window: 60
            periods: 0
            function: last
    - name: 'swift-api-check-failed'
      description: 'Endpoint check for swift-api is failed'
      severity: 'down'
      no_data_policy: 'skip' # the metric is only collected from the controller running the management VIP
      enabled: 'true'
      trigger:
        rules:
          - metric: openstack_check_api
            fields:
              service: 'swift-api'
            relational_operator: '=='
            threshold: 0
            window: 60
            periods: 0
            function: last
    - name: 'swift-s3-api-check-failed'
      description: 'Endpoint check for swift-s3-api is failed'
      severity: 'down'
      no_data_policy: 'skip' # the metric is only collected from the controller running the management VIP
      enabled: 'true'
      trigger:
        rules:
          - metric: openstack_check_api
            fields:
              service: 'swift-s3-api'
            relational_operator: '=='
            threshold: 0
            window: 60
            periods: 0
            function: last
    - name: 'keystone-public-api-check-failed'
      description: 'Endpoint check for keystone-public-api is failed'
      severity: 'down'
      no_data_policy: 'skip' # the metric is only collected from the controller running the management VIP
      enabled: 'true'
      trigger:
        rules:
          - metric: openstack_check_api
            fields:
              service: 'keystone-public-api'
            relational_operator: '=='
            threshold: 0
            window: 60
            periods: 0
            function: last
    - name: 'ceilometer-api-check-failed'
      description: 'Endpoint check for ceilometer-api is failed'
      severity: 'down'
      no_data_policy: 'skip' # the metric is only collected from the controller running the management VIP
      enabled: 'true'
      trigger:
        rules:
          - metric: openstack_check_api
            fields:
              service: 'ceilometer-api'
            relational_operator: '=='
            threshold: 0
            window: 60
            periods: 0
            function: last


  # Definition of the AFD node filters
  node_cluster_alarms:
    controller:
        apply_to_node: controller
        enable_notification: false
        activate_alerting: true
        alarms:
            cpu: ['cpu-critical-controller', 'cpu-warning-controller']
            network-rx: ['network-critical-dropped-rx', 'network-warning-dropped-rx']
            network-tx: ['network-critical-dropped-tx', 'network-warning-dropped-tx']
            root-fs: ['root-fs-critical', 'root-fs-warning']
            log-fs: ['log-fs-critical', 'log-fs-warning']
            other-fs: ['other-fs-critical', 'other-fs-warning']
            swap: ['swap-usage-critical', 'swap-activity-warning', 'swap-usage-warning']
            hdd-errors: ['hdd-errors-critical']
<% if @detach_rabbitmq_enabled -%>
    rabbitmq-nodes:
        apply_to_node: rabbitmq-nodes
        enable_notification: false
        activate_alerting: true
        alarms:
            cpu: ['cpu-critical-rabbitmq', 'cpu-warning-rabbitmq']
            network-rx: ['network-critical-dropped-rx', 'network-warning-dropped-rx']
            network-tx: ['network-critical-dropped-tx', 'network-warning-dropped-tx']
            root-fs: ['root-fs-critical', 'root-fs-warning']
            other-fs: ['other-fs-critical', 'other-fs-warning']
            swap: ['swap-usage-critical', 'swap-activity-warning', 'swap-usage-warning']
            hdd-errors: ['hdd-errors-critical']
<% end -%>
    mysql-nodes:
        apply_to_node: mysql-nodes
        enable_notification: false
        activate_alerting: true
        alarms:
<% if @detach_database_enabled -%>
            cpu: ['cpu-critical-mysql', 'cpu-warning-mysql']
            network-rx: ['network-critical-dropped-rx', 'network-warning-dropped-rx']
            network-tx: ['network-critical-dropped-tx', 'network-warning-dropped-tx']
            root-fs: ['root-fs-critical', 'root-fs-warning']
            other-fs: ['other-fs-critical', 'other-fs-warning']
            swap: ['swap-usage-critical', 'swap-activity-warning', 'swap-usage-warning']
            hdd-errors: ['hdd-errors-critical']
<% end -%>
            mysql-fs: ['mysql-fs-critical', 'mysql-fs-warning']
    compute:
        apply_to_node: compute
        enable_notification: false
        activate_alerting: true
        alarms:
            cpu: ['cpu-critical-compute', 'cpu-warning-compute']
            network-rx: ['network-critical-dropped-rx', 'network-warning-dropped-rx']
            network-tx: ['network-critical-dropped-tx', 'network-warning-dropped-tx']
            root-fs: ['root-fs-critical', 'root-fs-warning']
            nova-fs: ['nova-fs-critical', 'nova-fs-warning']
            other-fs: ['other-fs-critical', 'other-fs-warning']
            swap: ['swap-usage-critical', 'swap-activity-warning', 'swap-usage-warning']
            hdd-errors: ['hdd-errors-critical']
    storage:
        apply_to_node: storage
        enable_notification: false
        activate_alerting: true
        alarms:
            cpu: ['cpu-critical-storage', 'cpu-warning-storage']
            network-rx: ['network-critical-dropped-rx', 'network-warning-dropped-rx']
            network-tx: ['network-critical-dropped-tx', 'network-warning-dropped-tx']
            root-fs: ['root-fs-critical', 'root-fs-warning']
            other-fs: ['other-fs-critical', 'other-fs-warning']
            swap: ['swap-usage-critical', 'swap-activity-warning', 'swap-usage-warning']
            hdd-errors: ['hdd-errors-critical']
<% if @storage_options["volumes_ceph"] then -%>
            osd-disk: ['osd-disk-critical']
<% end -%>
    elasticsearch-nodes:
        apply_to_node: elasticsearch-nodes
        enable_notification: false
        activate_alerting: true
        alarms:
            cpu: ['cpu-critical-default']
            network-rx: ['network-critical-dropped-rx', 'network-warning-dropped-rx']
            network-tx: ['network-critical-dropped-tx', 'network-warning-dropped-tx']
            root-fs: ['root-fs-critical', 'root-fs-warning']
            data-fs: ['elasticsearch-fs-critical', 'elasticsearch-fs-warning']
            swap: ['swap-usage-critical', 'swap-activity-warning', 'swap-usage-warning']
            hdd-errors: ['hdd-errors-critical']
    influxdb-nodes:
        apply_to_node: influxdb-nodes
        enable_notification: false
        activate_alerting: true
        alarms:
            cpu: ['cpu-critical-default']
            network-rx: ['network-critical-dropped-rx', 'network-warning-dropped-rx']
            network-tx: ['network-critical-dropped-tx', 'network-warning-dropped-tx']
            root-fs: ['root-fs-critical', 'root-fs-warning']
            data-fs: ['influxdb-fs-critical', 'influxdb-fs-warning']
            swap: ['swap-usage-critical', 'swap-activity-warning', 'swap-usage-warning']
            hdd-errors: ['hdd-errors-critical']
    # This is the default alarms configured for all nodes with unknown roles
    default:
        apply_to_node: default
        # Operator wants to receive alert notification for individual nodes
        enable_notification: true
        activate_alerting: true
        alarms:
            cpu: ['cpu-critical-default']
            network-rx: ['network-critical-dropped-rx', 'network-warning-dropped-rx']
            network-tx: ['network-critical-dropped-tx', 'network-warning-dropped-tx']
            root-fs: ['root-fs-critical', 'root-fs-warning']
            other-fs: ['other-fs-critical', 'other-fs-warning']
            swap: ['swap-usage-critical', 'swap-activity-warning', 'swap-usage-warning']
            hdd-errors: ['hdd-errors-critical']

  # Definition of the AFD service filters
  service_cluster_alarms:
    rabbitmq-cluster:
        apply_to_node: rabbitmq-nodes
        enable_notification: false
        activate_alerting: true
        alarms:
            pacemaker: ['rabbitmq-pacemaker-down', 'rabbitmq-pacemaker-critical', 'rabbitmq-pacemaker-warning']
            queue: ['rabbitmq-queue-warning']
            memory: ['rabbitmq-memory-limit-critical', 'rabbitmq-memory-limit-warning']
            disk: ['rabbitmq-disk-limit-critical', 'rabbitmq-disk-limit-warning']
    rabbitmq-service:
        apply_to_node: rabbitmq-nodes
        enable_notification: false
        activate_alerting: true
        alarms:
            check: ['rabbitmq-check']
    mysql:
        apply_to_node: mysql-nodes
        enable_notification: false
        activate_alerting: true
        alarms:
            node-status: ['mysql-node-connected', 'mysql-node-ready']
            check: ['mysql-check']
    apache:
        apply_to_node: controller
        enable_notification: false
        activate_alerting: true
        alarms:
            worker: ['apache-warning']
            check: ['apache-check']
    nova-api:
        apply_to_node: controller
        enable_notification: false
        activate_alerting: true
        alarms:
            http_errors: ['nova-api-http-errors']
    nova-api-check:
        enable_notification: false
        activate_alerting: true
        alarms:
            vip: ['nova-api-check-failed']
    nova-logs:
        apply_to_node: controller
        enable_notification: false
        activate_alerting: true
        alarms:
            error: ['nova-logs-error']
    heat-api:
        apply_to_node: controller
        enable_notification: false
        activate_alerting: true
        alarms:
            http_errors: ['heat-api-http-errors']
    heat-api-check:
        enable_notification: false
        activate_alerting: true
        alarms:
            vip: ['heat-api-check-failed']
    heat-cfn-api-check:
        enable_notification: false
        activate_alerting: true
        alarms:
            vip: ['heat-cfn-api-check-failed']
    heat-logs:
        apply_to_node: controller
        enable_notification: false
        activate_alerting: true
        alarms:
            error: ['heat-logs-error']
<% if not @storage_options["objects_ceph"] then -%>
    swift-api:
        apply_to_node: controller
        enable_notification: false
        activate_alerting: true
        alarms:
            http_errors: ['swift-api-http-errors']
    swift-api-check:
        enable_notification: false
        activate_alerting: true
        alarms:
            vip: ['swift-api-check-failed']
    swift-s3-api-check:
        enable_notification: false
        activate_alerting: true
        alarms:
            vip: ['swift-s3-api-check-failed']
    swift-logs:
        apply_to_node: controller
        enable_notification: false
        activate_alerting: true
        alarms:
            error: ['swift-logs-error']
<% end -%>
    cinder-api:
        apply_to_node: controller
        enable_notification: false
        activate_alerting: true
        alarms:
            http_errors: ['cinder-api-http-errors']
    cinder-api-check:
        enable_notification: false
        activate_alerting: true
        alarms:
            vip: ['cinder-api-check-failed']
    cinder-v2-api-check:
        enable_notification: false
        activate_alerting: true
        alarms:
            vip: ['cinder-v2-api-check-failed']
    cinder-logs:
        apply_to_node: controller
        enable_notification: false
        activate_alerting: true
        alarms:
            error: ['cinder-logs-error']
    glance-api:
        apply_to_node: controller
        enable_notification: false
        activate_alerting: true
        alarms:
            http_errors: ['glance-api-http-errors']
    glance-api-check:
        enable_notification: false
        activate_alerting: true
        alarms:
            vip: ['glance-api-check-failed']
    glance-logs:
        apply_to_node: controller
        enable_notification: false
        activate_alerting: true
        alarms:
            error: ['glance-logs-error']
    neutron-api:
        apply_to_node: controller
        enable_notification: false
        activate_alerting: true
        alarms:
            http_errors: ['neutron-api-http-errors']
    neutron-api-check:
        enable_notification: false
        activate_alerting: true
        alarms:
            vip: ['neutron-api-check-failed']
    neutron-logs:
        apply_to_node: controller
        enable_notification: false
        activate_alerting: true
        alarms:
            error: ['neutron-logs-error']
    keystone-response-time:
        apply_to_node: controller
        enable_notification: false
        activate_alerting: true
        alarms:
            duration: ['keystone-response-time-duration']
    keystone-public-api:
        apply_to_node: controller
        enable_notification: false
        activate_alerting: true
        alarms:
            http_errors: ['keystone-public-api-http-errors']
    keystone-public-api-check:
        enable_notification: false
        activate_alerting: true
        alarms:
            vip: ['keystone-public-api-check-failed']
    keystone-logs:
        apply_to_node: controller
        enable_notification: false
        activate_alerting: true
        alarms:
            error: ['keystone-logs-error']
    keystone-admin-api:
        apply_to_node: controller
        enable_notification: false
        activate_alerting: true
        alarms:
            http_errors: ['keystone-admin-api-http-errors']
<% if @tls_enabled then -%>
    horizon-https:
<% else -%>
    horizon-web:
<% end -%>
        apply_to_node: controller
        enable_notification: false
        activate_alerting: true
        alarms:
            http_errors: ['horizon-web-http-errors']
    nova-instances:
        #TODO(scroiset): apply on compute nodes
        apply_to_node: controller
        enable_notification: false
        activate_alerting: true
        alarms:
            creation-time: ['instance-creation-time-warning']
    nova-free-vcpu:
        enable_notification: false
        activate_alerting: true
        alarms:
            nova-free-vcpu: ['total-nova-free-vcpu-warning']
    nova-free-memory:
        enable_notification: false
        activate_alerting: true
        alarms:
            nova-free-memory: ['total-nova-free-memory-warning']
    ceph-mon-cluster:
        apply_to_node: ceph-mon
        enable_notification: false
        activate_alerting: true
        alarms:
            health: ['ceph-health-critical', 'ceph-health-warning']
            capacity: ['ceph-capacity-critical', 'ceph-capacity-warning']
    ceph-mon-service:
        apply_to_node: ceph-mon
        enable_notification: false
        activate_alerting: true
        alarms:
            check: ['ceph-mon-check']
<% if @storage_options["volumes_ceph"] then -%>
    ceph-osd-service:
        apply_to_node: storage
        enable_notification: false
        activate_alerting: true
        alarms:
            check: ['ceph-osd-check']
<% end -%>
    elasticsearch-cluster:
        apply_to_node: elasticsearch-nodes
        enable_notification: false
        activate_alerting: true
        alarms:
            health: ['elasticsearch-health-critical', 'elasticsearch-health-warning']
    elasticsearch-service:
        apply_to_node: elasticsearch-nodes
        enable_notification: false
        activate_alerting: true
        alarms:
            check: ['elasticsearch-check']
    influxdb-service:
        apply_to_node: influxdb-nodes
        enable_notification: false
        activate_alerting: true
        alarms:
            check: ['influxdb-check']
    influxdb-api-check:
        enable_notification: false
        activate_alerting: true
        alarms:
            vip: ['influxdb-api-check-failed']
    haproxy-openstack:
        apply_to_node: controller
        enable_notification: false
        activate_alerting: true
        alarms:
            check: ['haproxy-check']
    pacemaker-service:
        apply_to_node: controller
        enable_notification: false
        activate_alerting: true
        alarms:
            check: ['pacemaker-check']
    libvirt-service:
        apply_to_node: compute
        enable_notification: false
        activate_alerting: true
        alarms:
            check: ['libvirt-check']
    memcached-service:
        apply_to_node: controller
        enable_notification: false
        activate_alerting: true
        alarms:
            check: ['memcached-check']
    ceilometer-api-check:
        enable_notification: false
        activate_alerting: true
        alarms:
            vip: ['ceilometer-api-check-failed']
