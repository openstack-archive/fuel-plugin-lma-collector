---
lma_collector:

  # GSE policies describe how the GSE cluster filters compute the status of a cluster
  #
  # A policy consists of a list of rules which are evaluated against the
  # current status of the cluster's members. When one rule matches, the cluster's
  # status gets the value associated with the rule and the evaluation stops.
  # The last rule of the list is usually a catch-all rule that defines the
  # default status in case no other rule matched.
  #
  # Policy rules looks like alarm rules except that:
  # - there are no 'metric', 'window' and 'period' parameter.
  # - there are only 2 functions: 'count' which returns the number of members with the given status
  gse_policies:
    # A policy defining that the cluster's status depends on the member with the
    # highest severity, typically used for a cluster of services.
    - highest_severity:
      - status: down
        trigger:
          logical_operator: or
          rules:
            - function: count
              arguments: [ down ]
              relational_operator: '>'
              threshold: 0
      - status: critical
        trigger:
          logical_operator: or
          rules:
            - function: count
              arguments: [ critical ]
              relational_operator: '>'
              threshold: 0
      - status: warning
        trigger:
          logical_operator: or
          rules:
            - function: count
              arguments: [ warning ]
              relational_operator: '>'
              threshold: 0
      - status: okay
        trigger:
          logical_operator: or
          rules:
            - function: count
              arguments: [ okay ]
              relational_operator: '>'
              threshold: 0
      - status: unknown

    # A policy defining that the cluster's status depends on the majority of its
    # members, typically used for clusters of nodes.
    - majority:
      - status: down
        trigger:
          logical_operator: or
          rules:
            - function: percent
              arguments: [ down ]
              relational_operator: '>'
              threshold: 50
      - status: critical
        trigger:
          logical_operator: or
          rules:
            - function: percent
              arguments: [ critical ]
              relational_operator: '>'
              threshold: 50
      - status: critical
        trigger:
          logical_operator: and
          rules:
            - function: percent
              arguments: [ critical ]
              relational_operator: '>'
              threshold: 0
            - function: percent
              arguments: [ okay ]
              relational_operator: '<'
              threshold: 50
              function: percent
      - status: warning
        trigger:
          logical_operator: or
          rules:
            - function: percent
              arguments: [ warning ]
              relational_operator: '>'
              threshold: 50
      - status: warning
        trigger:
          logical_operator: or
          rules:
            - function: percent
              arguments: [ okay ]
              relational_operator: '<'
              threshold: 50
              function: percent
      - status: okay

  gse_cluster_service:
    input_message_types:
      - afd_service_metric
    aggregator_flag: true
    # the field in the input messages to identify the cluster
    cluster_field: service
    # the field in the input messages to identify the cluster's member
    member_field: source
    output_message_type: gse_service_cluster_metric
    output_metric_name: cluster_service_status
    interval: 10
    warm_up_period: 20
    clusters:
      mysqld-tcp:
        policy: highest_severity
        members:
          - backends
      mysql:
        policy: majority_policy
        group_by_hostname: true
        members:
          - heartbeat
      haproxy:
        policy: majority_policy
        group_by_hostname: true
        members:
          - heartbeat
      apache:
        policy: majority_policy
        group_by_hostname: true
        members:
          - heartbeat
      memcached:
        policy: majority_policy
        group_by_hostname: true
        members:
          - heartbeat
      rabbitmq:
        policy: majority_policy
        group_by_hostname: true
        members:
          - heartbeat
          - memory
          - disk
          - queue
      nova-api:
        policy: highest_severity
        members:
          - backends
          - endpoint
          - http_errors
      nova-ec2-api:
        policy: highest_severity
        members:
          - backends
      nova-novncproxy-websocket:
        policy: highest_severity
        members:
          - backends
      nova-metadata-api:
        policy: highest_severity
        members:
          - backends
      nova-scheduler:
        policy: highest_severity
        members:
          - workers
      nova-cert:
        policy: highest_severity
        members:
          - workers
      nova-consoleauth:
        policy: highest_severity
        members:
          - workers
      nova-compute:
        policy: highest_severity
        members:
          - workers
      nova-conductor:
        policy: highest_severity
        members:
          - workers
      cinder-api:
        policy: highest_severity
        members:
          - backends
          - endpoint
          - http_errors
      cinder-v2-api:
        policy: highest_severity
        members:
          # Cinder V2 backends are in fact the same as the Cinder backends
          - endpoint
      cinder-scheduler:
        policy: highest_severity
        members:
          - workers
      cinder-volume:
        policy: highest_severity
        members:
          - workers
      neutron-api:
        policy: highest_severity
        members:
          - backends
          - endpoint
          - http_errors
      neutron-l3:
        policy: highest_severity
        members:
          - workers
      neutron-dhcp:
        policy: highest_severity
        members:
          - workers
      neutron-metadata:
        policy: highest_severity
        members:
          - workers
      neutron-openvswitch:
        policy: highest_severity
        members:
          - workers
      keystone-public-api:
        policy: highest_severity
        members:
          - backends
          - endpoint
          - http_errors
      keystone-admin-api:
        policy: highest_severity
        members:
          # TODO(pasquier-s): add a metric reporting the status of the keystone-admin-api endpoint
          - backends
          - http_errors
      glance-api:
        policy: highest_severity
        members:
          - backends
          - endpoint
          - http_errors
      glance-registry-api:
        policy: highest_severity
        members:
          - backends
      heat-api:
        policy: highest_severity
        members:
          - backends
          - endpoint
          - http_errors
      heat-cfn-api:
        policy: highest_severity
        members:
          - backends
          - endpoint
      heat-cloudwatch-api:
        policy: highest_severity
        members:
          - backends
<% if @tls_enabled then -%>
      horizon-https:
        policy: highest_severity
        members:
          - backends
<% else -%>
      horizon-ui:
        policy: highest_severity
        members:
          - backends
<% end -%>
<% if not @storage_options["objects_ceph"] then -%>
      swift-api:
        policy: highest_severity
        members:
          - backends
          - endpoint
          - http_errors
      swift-s3-api:
        policy: highest_severity
        members:
          # Swift S3 backends are in fact the same as the Swift backends
          - endpoint
<% end -%>
<% if @ceilometer_enabled -%>
      ceilometer-api:
        policy: highest_severity
        members:
          - backends
          - endpoint
<% end -%>

  gse_cluster_node:
    input_message_types:
      - afd_node_metric
    aggregator_flag: true
    # the field in the input messages to identify the cluster
    cluster_field: node_role
    # the field in the input messages to identify the cluster's member
    member_field: source
    output_message_type: gse_node_cluster_metric
    output_metric_name: cluster_node_status
    interval: 10
    warm_up_period: 80
    clusters:
      controller:
        policy: majority_policy
        group_by_hostname: true
        members:
          - cpu
          - fs
      compute:
        policy: majority_policy
        group_by_hostname: true
        members:
          - cpu
          - fs
      storage:
        policy: majority_policy
        group_by_hostname: true
        members:
          - cpu
          - fs

  gse_cluster_global:
    input_message_types:
      - gse_service_cluster_metric
      - gse_node_cluster_metric
    aggregator_flag: false
    # the field in the input messages to identify the cluster's member
    member_field: cluster_name
    output_message_type: gse_cluster_metric
    output_metric_name: cluster_status
    interval: 10
    warm_up_period: 30
    clusters:
      mysql:
        policy: highest_severity
        members:
          - mysqld-tcp
          - mysqld
          - controller
      haproxy:
        policy: highest_severity
        members:
          - haproxy
          - controller
      apache:
        policy: highest_severity
        members:
          - apache
          - controller
      memcached:
        policy: highest_severity
        members:
          - memcached
          - controller
      rabbitmq:
        policy: highest_severity
        members:
          - rabbitmq
          - controller
      nova:
        policy: highest_severity
        members:
          - nova-api
          - nova-ec2-api
          - nova-metadata-api
          - nova-scheduler
          - nova-compute
          - nova-conductor
          - nova-cert
          - nova-consoleauth
          - nova-novncproxy-websocket
          - controller
          - compute
        hints:
          - cinder
          - glance
          - keystone
          - neutron
      cinder:
        policy: highest_severity
        members:
          - cinder-api
          - cinder-v2-api
          - cinder-scheduler
          - cinder-volume
          - controller
          - storage
        hints:
          - keystone
      neutron:
        policy: highest_severity
        members:
          - neutron-api
          - neutron-l3
          - neutron-dhcp
          - neutron-metadata
          - neutron-openvswitch
          - controller
        hints:
          - keystone
      keystone:
        policy: highest_severity
        members:
          - keystone-public-api
          - keystone-admin-api
          - controller
        hints: []
      glance:
        policy: highest_severity
        members:
          - glance-api
          - glance-registry-api
          - controller
        hints:
          - keystone
      heat:
        policy: highest_severity
        members:
          - heat-api
          - heat-cfn-api
          - heat-cloudwatch-api
          - controller
        hints:
          - cinder
          - glance
          - keystone
          - neutron
          - nova
      horizon:
        policy: highest_severity
        members:
<% if @tls_enabled then -%>
          - horizon-https
<% else -%>
          - horizon-ui
<% end -%>
          - controller
        hints:
          - keystone
<% if not @storage_options["objects_ceph"] then -%>
      swift:
        policy: highest_severity
        members:
          - swift-api
          - swift-s3-api
          - controller
        hints:
          - keystone
<% end -%>
<% if @ceilometer_enabled -%>
      ceilometer:
        policy: highest_severity
        members:
          - ceilometer-api
          - controller
        hints:
          - keystone
<% end -%>
